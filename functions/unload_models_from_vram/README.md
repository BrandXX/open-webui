# Unload Models from VRAM

Welcome to the **Unload Models from VRAM** function for Open‚ÄëWebUI!  
This streamlined tool effortlessly frees GPU memory by unloading models through Ollama‚Äôs REST API. If your VRAM feels a bit crowded, clear it out with a single click‚Äîthink of it as spring‚Äëcleaning for your digital workspace. üòâ

---

## Overview

This function:

- **Retrieves Loaded Models:** Calls `/api/ps` to list models currently in VRAM.  
- **Unloads Each Model:** Sends a POST to `/api/generate` (`prompt:""`, `keep_alive:0`, `stream:false`) for every model found.  
- **One‚ÄëClick Action:** Just hit the ‚ÄúUnload Models from VRAM‚Äù button‚Äîno extra confirmation screens.  
- **Configurable Settings:** Endpoint URL, time‚Äëouts, SSL verification, delay, and logging level are all adjustable.  
- **Robust Error Handling:** Clear emitter messages and detailed logs help you troubleshoot misconfigurations, time‚Äëouts, or connection issues.  
- **Progress Feedback:** Real‚Äëtime status updates (with a progress bar) keep you informed while each model unloads.

---

## Features

| Feature | Description |
|---------|-------------|
| **REST API Integration** | Seamlessly interacts with Ollama‚Äôs API. |
| **Configurable Endpoint & Time‚Äëout** | Defaults: `http://host.docker.internal:11434`, `3‚ÄØs`. |
| **SSL Verification Toggle** | `VERIFY_SSL` valve lets you enable or disable TLS cert checks. |
| **Adjustable Logging Level** | `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`. |
| **Selective Unload** | Pass a `models` list in the request body to unload just one or two heavyweights. |
| **Delay Between Unloads** | Optional (default 200‚ÄØms) delay ensures the UI renders progress nicely. |
| **Graceful Error Handling** | Concise user messages + verbose logs when you need them. |
| **Asynchronous Operation** | Non‚Äëblocking design keeps the chat UI responsive. |

---

## Configuration

| Valve | Default | Purpose |
|-------|---------|---------|
| `OLLAMA_ENDPOINT` | `http://host.docker.internal:11434` | Base URL of the Ollama REST API. |
| `REQUEST_TIMEOUT` | `3` seconds | HTTP request time‚Äëout. |
| `UNLOAD_DELAY_MS` | `200` | Wait time between model unloads (set `0` for maximum speed). |
| `VERIFY_SSL` | `true` | Toggle TLS certificate verification. |
| `LOG_LEVEL` | `INFO` | Logging verbosity. |

- **Version:** `1.1.2`  
- **Required Open‚ÄëWebUI Version:** `0.3.9`

---

## How It Works

1. **Trigger Action**  
   Click the *Unload Models from VRAM* button (next to ‚ÄúRegenerate‚Äù) to start.

2. **Retrieve Models**  
   A GET request to `{OLLAMA_ENDPOINT}/api/ps` fetches the current VRAM residents.

3. **Unload Loop**  
   For each model, a POST to `{OLLAMA_ENDPOINT}/api/generate` with payload  
   ```json
   { "model": "<name>", "prompt": "", "keep_alive": 0, "stream": false }
   ```  
   frees the GPU memory. A short delay (`UNLOAD_DELAY_MS`) lets the UI breathe.

4. **Error & Progress Reporting**  
   Status events show which model is unloading and how far you‚Äôve progressed. Problems (timeouts, bad URLs, etc.) surface in‚Äëchat and in logs.

---

## Usage Instructions

1. **Click and Go**  
   Hit the *Unload Models from VRAM* icon ‚Üí models start unloading immediately.

2. **Watch the Progress Bar**  
   A live counter shows how many models remain. When it hits 100‚ÄØ%, you‚Äôre done.

---

## Checking Logs

```bash
# Docker example
docker logs <open-webui_container> --follow
```

Set `LOG_LEVEL=DEBUG` for the deepest insights, or stick with `INFO` for day‚Äëto‚Äëday use.

---

## Code Overview

Built with:

- **`requests`** ‚Äì HTTP calls to Ollama.  
- **`asyncio`** ‚Äì Keeps the chat UI fluid.  
- **`pydantic`** ‚Äì Validates and documents valves.  
- **`logging`** ‚Äì Structured logs for easy troubleshooting.

---

## Changelog

- **Version 1.1.2**  
  - Added `UNLOAD_DELAY_MS` valve to control a short pause between unloads (default‚ÄØ200‚ÄØms) so progress updates aren‚Äôt skipped.  
  - Introduced custom toolbar icon via `icon_url` header (Lucide ‚Äúmonitor‚Äëdown‚Äù SVG embedded as Base‚Äë64 data URI, fully offline‚Äëfriendly).  

- **Version 1.1.1** **("DEV")**  
  - Restored inner `Valves` class (action button visible again).  
  - Introduced `VERIFY_SSL` valve for secure API calls.  
  - Added `stream:false` to unload payload for faster single‚ÄëJSON responses.  
  - Implemented progress emission and optional *selective unload* via request body.  
  - Upgraded logging initialization (`logging.basicConfig`).  

- **Version 1.0.1**  
  - Removed confirmation prompt for faster operation.  
  - Added configurable logging level valve.  

- **Version 1.0.0**  
  - Initial release with robust error handling, emitter feedback, and async design.

---

## Contributions

Have an idea? Found a bug? Open a pull request or issue on [GitHub](https://github.com/BrandXX/open-webui/).  
First‚Äëtimers welcome‚Äîlet‚Äôs build something great together!

---

## License

MIT License ‚Äî see `LICENSE` for details.

---

## Acknowledgments

Huge thanks to the Open‚ÄëWebUI community and contributors for your constant improvements. You rock!

---

Happy unloading, and enjoy your tidy VRAM! üòÑüöÄ

